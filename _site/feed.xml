<?xml version="1.0" encoding="utf-8"?><feed xmlns="http://www.w3.org/2005/Atom" ><generator uri="https://jekyllrb.com/" version="4.2.2">Jekyll</generator><link href="http://localhost:4000/feed.xml" rel="self" type="application/atom+xml" /><link href="http://localhost:4000/" rel="alternate" type="text/html" /><updated>2024-08-21T12:52:40+01:00</updated><id>http://localhost:4000/feed.xml</id><title type="html">Accelerate Programme</title><subtitle>Advancing scientific discovery with machine learning.</subtitle><entry><title type="html">How can we … use AI to redesign crutches?</title><link href="http://localhost:4000/2024/06/27/how-can-we-use-ai-to-redesign-crutches.html" rel="alternate" type="text/html" title="How can we … use AI to redesign crutches?" /><published>2024-06-27T12:55:00+01:00</published><updated>2024-06-27T12:55:00+01:00</updated><id>http://localhost:4000/2024/06/27/how-can-we-%E2%80%A6-use-ai-to-redesign-crutches</id><content type="html" xml:base="http://localhost:4000/2024/06/27/how-can-we-use-ai-to-redesign-crutches.html"><![CDATA[<p>By 2050, more than one billion people will have used a mobility aid including crutches, which tend to be uncomfortable and can even cause secondary injuries from joint and muscle pain to skin irritation and carpal tunnel syndrome. We set out to redesign crutches used by the NHS to address problems of instability, effort and pain, using machine learning to discover more optimal geometry that can be personalised for patients.</p>

<p><strong>Setting our course</strong></p>

<p>Our research to explore the use of machine learning to redesign crutches formed our final project for the <a href="https://mlatcl.github.io/teaching/">ML and the Physical World</a> module, taught by Neil Lawrence and Carl Henrik Ek. This course, which is part of the  MPhil in Advanced Computer Science, encouraged us to apply probabilistic machine learning, specifically Gaussian Processes, to real-world problems. Crutches were a natural choice because not only did they give us a technical challenge that would test what we learned on the course, but I (Dr Conci) had previously been involved with the Andrew Simpson Sport Enabling Trust, which aims to redesign crutches in memory of Engineering student Andrew Simpson who was diagnosed with an aggressive bone cancer, which led to an upper knee amputation.</p>

<p>Continuing the work of the Engineering Design Team at Cambridge in creating prototype crutches, we set out to investigate whether we could use Gaussian Processes and Bayesian Optimisation to generate hypotheses about novel crutch geometries.</p>

<p><strong>Starting point/ You can’t improve what you can’t measure</strong></p>

<p>Creating a personalised crutch geometry is essentially a search optimisation problem. Out of all the possible geometries we needed to rapidly discover which one fits ‘best’. So first, we set out to define what ‘best’ means, and then we needed to iterate efficiently to find it. We defined the quality of a crutch geometry by combining subjective and objective measures of effort, instability and pain after a 90-step crutching bout. The objective metrics were derived by the accelerometer data of a H10 heart rate monitor. These combined subjective and objective metrics defined our ‘loss metric’ that we aimed to minimise.</p>

<p>When it comes to optimising this metric, mathematically deriving a model to capture such complexity is intractable. Moreover, there is a scarcity of large datasets, which limits the application of conventional data-hungry machine learning methods. Gaussian Processes and their integration with Bayesian Optimisation became our key solution. We collaborated with Dr Christof Schwiening at the Physiology, Development and Neuroscience Department at the University of Cambridge to design and manufacture a flexible crutch. By adjusting three parameters this flexible crutch can effectively turn into any crutch potentially useful geometry. We then asked participants to test the standard NHS (Lofstrand) elbow crutch and the Smart Crutch, which is currently on the market as a replacement to the standard NHS.</p>

<p>Once we had a loss metric for these standard crutches, we fed them to our Bayesian optimiser with the crutch parameters, enabling the model to suggest the next set of crutch parameters to test. We then fed the suggested new parameters into a simulator to assess whether the AI’s crutch geometry was possible, and if it was, set up our flexible crutch to match. We could then run the suggested physical experiment, collecting qualitative and quantitative data to generate a new person- and geometry-specific loss, which could be analysed by the model again. Each new experiment, therefore, provides new information that brings us closer to finding the optimal crutch geometry for that participant.</p>

<p><strong>Results</strong></p>

<p>With as few as five crutching bouts, our Bayesian optimiser managed to identify a novel geometry that was 35% better on instability, effort and pain compared to the standard crutch for our participant.  The new geometry brought the user’s elbow back and the handle downwards, creating a shape that is very different to the NHS offering, and yet substantially better.</p>

<p>How can we explain this novel design? Firstly, with a wrist angle about 30 degrees wider than the NHS’ right-angled design, the geometry offers a much stronger and more comfortable wrist position. Second, due to its geometry, there is a large forward moment which helps you move forward with minimal effort. This needs to be carefully managed so the crutch doesn’t throw you forward but rather aids in stability.</p>

<p>When you look at the model’s design, it’s not a geometry that immediately comes to mind. That’s a big advantage of using an AI process for design. After defining our loss metric and specific algorithm, we can let it find the optimal geometry without further bias of what it ‘should’ look like. This can provide some excellent, unexpected, and sometimes ‘creative’ results reminiscent of AlphaGo’s move 37.</p>

<p><strong>Next steps</strong></p>

<p>We won an award for our use of machine learning to revolutionise crutch design  and would like to take the project further, meeting the challenges of tailoring geometries to meet individual needs and enabling our personalised crutch to be manufactured for the same cost as the NHS one, which is approximately £10. 
The most exciting aspect of this work is the potential to scale across people. As more data is gathered among individuals with similar characteristics to previous users, it will become easier to discover their personal crutch geometry.</p>

<p>We plan to conduct a clinical trial with unencumbered participants initially, allowing us to iterate and improve our designs. Ultimately, we want to validate our designs with patients at Addenbrookes Fracture Clinic through a prospective clinical trial, so that one day, anyone who needs to use crutches, can recover without further pain and harm.</p>]]></content><author><name>Dr Riccardo Conci &amp; Riccardo Ali, M.Phil in Advanced Computer Science, Department of Computer Science and Technology </name></author><summary type="html"><![CDATA[By 2050, more than one billion people will have used a mobility aid including crutches, which tend to be uncomfortable and can even cause secondary injuries from joint and muscle pain to skin irritation and carpal tunnel syndrome. We set out to redesign crutches used by the NHS to address problems of instability, effort and pain, using machine learning to discover more optimal geometry that can be personalised for patients.]]></summary><media:thumbnail xmlns:media="http://search.yahoo.com/mrss/" url="http://localhost:4000/assets/uploads/updated-image-how-can-we-use-ai-to-redesign-crutches.png" /><media:content medium="image" url="http://localhost:4000/assets/uploads/updated-image-how-can-we-use-ai-to-redesign-crutches.png" xmlns:media="http://search.yahoo.com/mrss/" /></entry><entry><title type="html">Advancing knowledge about embodied AI and bio-inspired evolutionary soft robotics</title><link href="http://localhost:4000/2024/06/20/advancing-knowledge-about-embodied-ai-and-bio-inspired-evolutionary-soft-robotics.html" rel="alternate" type="text/html" title="Advancing knowledge about embodied AI and bio-inspired evolutionary soft robotics" /><published>2024-06-20T10:00:00+01:00</published><updated>2024-06-20T10:00:00+01:00</updated><id>http://localhost:4000/2024/06/20/advancing-knowledge-about-embodied-ai-and-bio-inspired-evolutionary-soft-robotics</id><content type="html" xml:base="http://localhost:4000/2024/06/20/advancing-knowledge-about-embodied-ai-and-bio-inspired-evolutionary-soft-robotics.html"><![CDATA[<p>Embodied artificial intelligence (EAI) brings AI, robotics, and bioengineering together. Embodiment in artificial intelligence is foundational for the mechanical execution of tasks and to achieve a higher order of situational and adaptive intelligence.</p>

<p>EAI is rooted in the idea that true intelligence transcends information processing to encompass physical and social interactions. Interacting with the physical world requires a body. Embodiment enables tangible robots to understand and adapt to complex environment.</p>

<p>Within the field, evolutionary soft robotics merges evolutionary algorithms and the analytical benefits of AI with the mechanical sophistication of robotics. This niche - which is my current area of interest - focuses on the harmonious integration of sensing, mechanics, and control within soft structures while highlighting the complex interplay between embodied intelligence and artificial constructs.</p>

<p>Evolutionary soft robotics enables the development of robots that are flexible, resilient and capable of self-improvement over time by integrating evolutionary algorithms which simulate the process of natural. This means that they can adapt their behaviour based on environmental feedback without human intervention. Such advanced robots with EAI that could one day be part of our everyday lives.</p>

<p><strong>Sharing knowledge</strong></p>

<p>The field of EAI is emerging, making it extremely beneficial to share knowledge across the community to drive progress. Using funding from the Accelerate Programme for Scientific Discovery and the Cambridge Centre for Data Driven Discovery (C2D3), I organised a <a href="https://birlab.org/embodied-artificial-intelligence-and-evolutionary-soft-robotics-workshop-6-march-2024-invitation-only/">workshop</a> on 6 March 2024 exploring the intersection of EAI and Evolutionary Soft Robotics.</p>

<p>There were 25 participants, including PhD students from Cambridge and EPFL, early-stage researchers from Cambridge, EPFL and Edinburgh Napier University, and professors from USA, AU, EU and UK. The funding allowed us to bring together an international field of experts who shared diverse perspectives at the cutting edge of these fields.</p>

<p>The core idea of our workshop was to discuss the application of embodied AI in evolutionary soft robotics and how we can combine ideas and actions, theory and practice to uncover the latent potential of embodied AI, and shape the trajectory of AI-driven robotics.</p>

<p>We focused on leveraging AI and evolutionary strategies to enhance the adaptability, efficiency and functionality of soft robots. We explored several key research directions, including optimising soft robotic designs for diverse environmental conditions and developing more sophisticated control algorithms for real-time adaptability.
Speakers from the universities of Bristol, Edinburgh Napier, Vermont and Vrije University Amsterdam as well as Imperial College London, CSIRO and PFL shared their expertise. For example, David Howard of CSIRO and Josh Bongard  from the University of Vermont highlighted the integration of AI techniques in the design and optimization of soft robots, with Howard speaking about how AI can enhance the design process, and Bongard detailing how maintaining effective gradient flows in differentiable programming is crucial for optimising soft robot designs in real-time.</p>

<p><br />
The design process of robots and real-time optimisation are critical because they enable the creation of robots that can adapt to changing environments and perform tasks more efficiently.  For example, in industrial settings, a robot with an enhanced design process can handle a wide range of products on an assembly line, improving productivity and reducing downtime due to reconfiguration.</p>

<p>The workshop gave me the opportunity to showcase my ideas in front of an engaged audience, while receiving feedback from peers and experts has helped me refine my approach and think more critically. These skills will be essential as I take forward my research in this area  . Furthermore, organising and managing an international conference gave me invaluable experience in project management and coordinating logistics, facilitating cross-disciplinary collaboration, and fostering a sense of community among researchers.</p>

<p><strong>My research</strong></p>

<p>My research centres on EAI and more specifically, evolutionary robotics. I’m concerned with how to design a robot’s control centre or ‘brain’ as well as its morphologies. I use AI in every part of my work to build robots. I used deep learning, or reinforced learning to train the control centres of the machines, but I also use it to design morphologies of robots without the need for any human experience. We call this bio inspired robotics design framework.</p>

<p>Currently, I am working on a hand with grippers, the shape of which is inspired by a fish fin. A gripper like ours has many potential industrial and agricultural applications. For example, it could be used to handle and pack fragile items like glassware, or for harvesting fruit and vegetables without bruising or spoiling produce.
My team’s work on the <a href="https://www.researchgate.net/publication/379190012_Fin-QD_A_Computational_Design_Framework_for_Soft_Grippers_Integrating_MAP-Elites_and_High-fidelity_FEM">fin ray soft gripper</a>, proposes an automated computational design optimization framework that generates gripper diversity to individually grasp geometrically distinct object types based on a quality-diversity approach.</p>

<p>It first discusses a large design space including 28 design parameters for a finger-based soft gripper, including the rarely-explored design space of finger arrangement. Then, a contact-based Finite Element Modelling (FEM) is proposed in a simulation software called SOFA   (Simulation Open Framework Architecture) to output high-fidelity grasping data for fitness evaluation and feature measurements. Finally, diverse gripper designs are obtained from the framework while considering features such as the volume and workspace of grippers. This work bridges the gap of computationally exploring the vast design space of finger-based soft grippers, while grasping large geometrically distinct object types with a simple control scheme.</p>

<p>The work advances how computational design can be used in my field of EAI and soft robotics, as well as the frame design space. This field is crucial for applications in healthcare, manufacturing, and agriculture, where robots need precision and adaptability.</p>

<p><strong>The future</strong></p>

<p>The future of embodied artificial intelligence holds transformative potential, extending far beyond the current horizons of robots and AI. It could lead to autonomous agricultural robots that could more efficiently tend to crops, or robots that could navigate hazardous environments to conduct search and rescue operations in the aftermath of natural disasters.</p>

<p>I already have a lot of collaborations planned, as well as upcoming workshops, including our next event at a <a href="https://gecco-2024.sigevo.org/Workshops">major computer science conference</a> in Melbourne, We are currently calling for <a href="https://eai-evlsoro.github.io/#cfp">contributions</a> for this event, which aims to fuse theoretical computer science with practical EAI solutions. By bridging these disciplines, we hope to unlock new efficiencies and capabilities, such as leveraging advanced theoretical algorithms could lead to the development of more autonomous, decision-making robots that can adapt and learn from their environments in unprecedented ways.</p>

<p>We imagine a time when robots can help us with everything. One ongoing project in our lab is to create a chef robot to help with making dinner, but robots could help us communicate too. There are so many opportunities and hopefully, the workshop might help make some of them reality. From medical robots with arms that can adapt to surgical tasks and support in varied procedures, to robotic chefs, who knows what we can cook up!.</p>

<p>Learn more about the <a href="https://gecco-2024.sigevo.org/Workshops">conference</a> taking place in July 2024. 
<a href="https://eai-evlsoro.github.io/#cfp">Call for contributions</a></p>

<p><em>Y﻿ue was awarded funding through the Accelerate-C2D3 funding call. Find out more about the 2024 call for proposals <a href="https://acceleratescience.github.io/news/2024-05-20-accelerate-c2d3-funding-call-for-novel-applications-of-ai-for-research-and-innovation-2024.html">here</a> and apply by 18 September.</em></p>]]></content><author><name>By Yue Xie, Marie Sklodowska-Curie Future Roads Fellow, Bio-Inspired Robotics Laboratory, Department of Engineering</name></author><summary type="html"><![CDATA[The field of Embodied Artificial Intelligence is emerging, making it extremely beneficial to share knowledge across the community to drive progress. Using funding from the Accelerate Programme for Scientific Discovery and the Cambridge Centre for Data Driven Discovery (C2D3), I organised a workshop on 6 March 2024 exploring the intersection of EAI and Evolutionary Soft Robotics.]]></summary><media:thumbnail xmlns:media="http://search.yahoo.com/mrss/" url="http://localhost:4000/assets/uploads/yue-xie-blog-post-1-.jpg" /><media:content medium="image" url="http://localhost:4000/assets/uploads/yue-xie-blog-post-1-.jpg" xmlns:media="http://search.yahoo.com/mrss/" /></entry><entry><title type="html">Towards broad generalization in machines</title><link href="http://localhost:4000/2024/04/22/towards-broad-generalization-in-machines.html" rel="alternate" type="text/html" title="Towards broad generalization in machines" /><published>2024-04-22T10:00:00+01:00</published><updated>2024-04-22T10:00:00+01:00</updated><id>http://localhost:4000/2024/04/22/towards-broad-generalization-in-machines</id><content type="html" xml:base="http://localhost:4000/2024/04/22/towards-broad-generalization-in-machines.html"><![CDATA[<p>AI today powers everything from your phone’s autocorrect to your YouTube feed. However, all these models have one thing in common: they’re very good at doing things in their training dataset, and are very bad at things outside it. A particular example of this is self-driving cars, which were “nearly there” 6 years ago [1] and have made surprisingly little progress since. The difficulty is that AI systems underperform when met with unexpected situations outside their training data (like a tree fallen on a road). To build more robust, safe and versatile AI systems, we need to build models that are more intelligent, and can perform reasoning to solve novel situations in the way that me and you effortlessly do every day. But building such intelligence is a daunting task (even defining intelligence is hard!), so where do we start? <a href="https://acceleratescience.github.io/team/soumya-banerjee.html">Dr Soumya Banerjee</a>, Senior Research Associate in the Accelerate Programme worked with MPhil student Mikel Bober-Irizar as part of the Unconventional Approaches to AI course on the MPhil in Advanced Computer Science. This work explored new ways machine learning systems can tackle abstraction and reasoning tasks.</p>

<p><strong>A long journey to intelligence</strong></p>

<p>In 1967, long before the advent of AI like we know it today, Mikhail Bongard published Pattern Recognition, noting how scientists such as Alan Turing have long posited the concept of a thinking machine; but while machines can be built to solve specific tasks (such as solving quadratic equations or playing chess), no progress had been made to imitate or even understand the ability of us humans to adapt to new situations. Bongard suggests that pattern recognition, the ability to decompose situations into objects and concepts, is central to the abilities of human intelligence.</p>

<p>Bongard introduced a set of logic puzzles (known now as the Bongard Problems) which were designed to test whether a (hypothetical future) machine can perform the sort of logical reasoning that we take for granted each day. Each problem has 12 images, split into two groups. The goal of each problem is to answer the question: “What sets apart these two sets of images?” Can you solve these <a href="https://github.com/neelsoumya/arc_paper_blog/blob/main/Picture_1.png">Bongard problems</a>[﻿2]?</p>

<p>Over 50 years later, a machine that can solve these types of problems has yet to surface. It turns out that modern machine learning algorithms are exceptionally good at learning patterns in large training data, but struggle to generalise to unseen situations that never appeared during training.</p>

<p>In 2019, Francois Chollet called this ability broad generalisation, and introduced a new more rigorous benchmark, the Abstraction &amp; Reasoning Corpus (ARC), against which computer systems can be tested. Similarly to the Bongard Problems, ARC problems ask people (or computers!) to solve logic puzzles involving colourful grids, where each problem involves learning a transformation from 3-5 examples and applying it to a test input to produce an output grid that must be pixel-perfect as in <a href="https://github.com/neelsoumya/arc_paper_blog/blob/main/Picture_2.png">these examples.</a></p>

<p>There have been three international competitions on ARC with over $100,000 in prizes, but we’ve yet to see a machine-learning-based solution that can solve a significant portion of ARC problems: the best solutions (while impressive) instead rely on hand-crafted rules and heuristics. From an ML perspective, we’ve got as little as 3 training examples and 10300 possible outputs.</p>

<p><strong>A new approach</strong></p>

<p>In my Masters project, I looked at two new ways that a machine-learning system could be used to solve ARC tasks.</p>

<p>The first is a system called <a href="https://royalsocietypublishing.org/doi/10.1098/rsta.2022.0050">DreamCoder </a>(originally built by MIT), which uses neural networks to write computer programs that represent transformations, which we adapted to work on ARC tasks. By defining a programming language of potentially useful primitives (like rotation, filling in), DreamCoder is able to compose these into complex transformations. A neural network trained on “dreamed” problems looks at a task and suggests which transformations to try next, massively reducing the exponential search space. Our language, PeARL (Perceptual Abstration and Reasoning Language), allows DreamCoder to use higher-order functions and lists in its solutions.</p>

<p>Here’s an example of a task solved by DreamCoder. It first constructs a function that says “set the background to orange”, and then applies this function individually to each object in the grid, before overlaying them on their original positions. This program gives the correct output for the test example! Details of this example can be seen here.</p>

<p><strong>What’s next?</strong></p>

<p>Imparting abstraction and reasoning abilities into our machine learning models remains an unsolved and elusive touchstone problem, and is likely to remain so for some time. However, we see two very different avenues can both make progress: a complex symbolic reasoning system harnessing neural networks (like DreamCoder), as well as relying on the emergent reasoning capabilities of extremely large foundation models  (we note that there is a very lively debate on whether foundation models have reasoning capabilities). When we crack this problem, it will be fascinating to see on which side we end up.</p>

<p>If you want to learn more about this work, please read <a href="https://arxiv.org/abs/2402.03507">our paper.</a></p>

<p>Bober-Irizar, M. and Banerjee, S., 2024. <em>Neural networks for abstraction and reasoning: Towards broad generalization in machines.</em> arXiv preprint arXiv:2402.03507.</p>

<p>[1] <a href="https://www.theverge.com/2018/7/3/17530232/self-driving-ai-winter-full-autonomy-waymo-tesla-uber">https://www.theverge.com/2018/7/3/17530232/self-driving-ai-winter-full-autonomy-waymo-tesla-uber </a></p>

<p>[2] If you’re interested in learning more about Bongard Problems, or the solutions, check out Harry Foundalis’ diligent collection: <a href="http://www.foundalis.com/res/bps/bpidx.htm">http://www.foundalis.com/res/bps/bpidx.htm</a></p>]]></content><author><name>By Soumya Banerjee, Senior Research Associate, Accelerate Programme for Scientific Discovery and Mikel Bober-Irizar, MPhil student in Advanced Computer Science</name></author><summary type="html"><![CDATA[AI today powers everything from your phone's autocorrect to your YouTube feed. However, all these models have one thing in common: they're very good at doing things in their training dataset, and are very bad at things outside it. A particular example of this is self-driving cars, which were "nearly there" 6 years ago and have made surprisingly little progress since. The difficulty is that AI systems underperform when met with unexpected situations outside their training data (like a tree fallen on a road). To build more robust, safe and versatile AI systems, we need to build models that are more intelligent, and can perform reasoning to solve novel situations in the way that me and you effortlessly do every day. But building such intelligence is a daunting task (even defining intelligence is hard!), so where do we start? Dr Soumya Banerjee, Senior Research Associate in the Accelerate Programme worked with MPhil student Mikel Bober-Irizar as part of the Unconventional Approaches to AI course on the MPhil in Advanced Computer Science. This work explored new ways machine learning systems can tackle abstraction and reasoning tasks.]]></summary><media:thumbnail xmlns:media="http://search.yahoo.com/mrss/" url="http://localhost:4000/assets/uploads/soumyamikel-blog-image-april-2024-1-.jpg" /><media:content medium="image" url="http://localhost:4000/assets/uploads/soumyamikel-blog-image-april-2024-1-.jpg" xmlns:media="http://search.yahoo.com/mrss/" /></entry><entry><title type="html">Could we… use AI to find bat viruses in museum specimens?</title><link href="http://localhost:4000/machine-learning/2024/03/18/could-we-use-ai-to-find-bat-viruses-in-museum-specimens.html" rel="alternate" type="text/html" title="Could we… use AI to find bat viruses in museum specimens?" /><published>2024-03-18T09:22:00+00:00</published><updated>2024-03-18T09:22:00+00:00</updated><id>http://localhost:4000/machine-learning/2024/03/18/could-we%E2%80%A6-use-ai-to-find-bat-viruses-in-museum-specimens</id><content type="html" xml:base="http://localhost:4000/machine-learning/2024/03/18/could-we-use-ai-to-find-bat-viruses-in-museum-specimens.html"><![CDATA[<p>Bats comprise around one in five named mammal species and are found on every continent except Antarctica. In recent decades, bats have been implicated as potential hosts of several viruses that cause high fatality rates in humans. Still, despite years of research, there’s a lot we don’t know about bat virus ecology, hindering the ability of experts to anticipate and prepare for the next potential pandemic.</p>

<p>A repository of untapped data could help shed light on the relationship between bat ecology and viral emergence. In my project, supported by the Accelerate and Cambridge Centre for Data Driven Discovery funding call, I am exploring using AI and natural history museum collections for host prediction and viral surveillance.</p>

<p><strong>An emerging field</strong></p>

<p>I study fruit bats and paramyxoviruses, a family of viruses that includes the human mumps virus as well as some known zoonotic viruses hosted by bats (e.g., Hendra virus and Nipah virus). I’m working on a proof-of-concept study using machine learning to predict and test which of these bats are most likely to host certain paramyxoviruses.</p>

<p>One approach for host identification is to retrospectively sample wild animals immediately following a disease outbreak in the vicinity, but that is difficult, expensive, time-consuming, and invasive. Instead, my colleagues and I propose conducting proactive pathogen surveillance in natural history collections, where millions of specimens are already available for screening.</p>

<p>This is an emerging field. There are various challenges associated with extracting viruses, bacteria, and parasites from stuffed specimens in dusty cases and pickled creatures in jars—namely limitations caused by the age and preservation type of the specimens. However, there is also great potential in this line of work, as these historical specimens provide snapshots of host-pathogen interactions across space and time. For our initial project, we are focusing on specimens with associated frozen tissue samples (typically collected within the last three decades) housed at natural history museums in Chicago and New York.</p>

<p><strong>Using AI and experimenting with data</strong></p>

<p>Honing in on suitable samples within vast natural history collections is like searching for a needle in a haystack. It’s overwhelming. Where do you start and how do you guess which species are likely to host a virus? To focus our sampling, we are using machine learning to predict likely paramyxovirus host species within the fruit bat family (Pteropodidae). This involves gathering ecological trait data for each of the ~200 species of bats in this family—information like body size, diet, habitat, reproductive cycles, etc.—and using an algorithm to detect patterns in which types of bats are more likely to host viruses. For example, the model may suggest that smaller and more geographically widespread fruit bats are more likely to host paramyxoviruses. We can then use this “trait profile” to identify likely host species that have thus far never been sampled for viruses.</p>

<p>So far, the project has been computationally manageable, because we’ve chosen to run it on a small subset of viruses and a small subset of bats. We are using a type of machine learning algorithm called boosted regression trees, which is particularly good at handling missing data (a big problem in ecological research) and identifying patterns. This is fairly exploratory, hypothesis-generating research, and at the moment we are fine-tuning our model before we use the outputs to target specimens for screening. If some of these specimens test positive, we can then update the data we are feeding into our algorithm to reflect these “novel” hosts, thereby creating a dynamically updated AI pipeline with increasingly accurate predictions.</p>

<p>The funding from the Accelerate Programme will be incredibly helpful for the next stage of our work. It will support my travel to museums and the lab costs of extracting and sequencing viral RNA from several hundred chosen specimens. We may also tap into the expertise of the Accelerate Programme’s AI Clinic if we hit any roadblocks with modelling. It’s particularly helpful to know that we can access technical troubleshooting resources, as this project lies at the intersection of disease ecology and collections-based work—neither of which are historically computationally intensive.</p>

<p><strong>Our aim</strong></p>

<p>We hope that the model will first accurately predict known paramyxovirus host species based on their ecology. Based on these ecological trait patterns, it will then generate a list of “novel” suspected hosts, which we plan to use to guide our search for viruses in museum collections. For example, we could screen ~50 specimens of each of the top ten predicted “novel” host species for viral RNA. I’m only looking for one family of viruses in one family of bats, since this is a small-scale proof-of-concept study. However, more broadly, I hope that this study lays out a framework for using machine learning and trait-based modelling to guide viral surveillance in collections.</p>

<p>This project will form a chapter of my PhD thesis. It would be exciting to find some novel hosts in museum collections that we would not have found without using AI to sort through a massive amount of data and generate predictions. However, even if none of the specimens test positive, the predictions themselves will be publishable and will accelerate knowledge in this area. For example, we can map the ranges of these predicted host species and assess the degree of their spatial overlap with humans, which has consequences for downstream viral spillover risk.</p>

<p><strong>Looking to the future</strong></p>

<p>What I like about this project conceptually is that we’re using modern technology to unlock new data from old specimens and make the most of existing resources by exploring cutting-edge computational methods.
Our study could open the door for proactive host identification in collections before outbreaks occur. Museum collections also offer something different from field-based sampling: a broad spatial and temporal range of host-virus associations.</p>

<p>I hope that one day museums can function as historical libraries of host-pathogen associations. Ideally, this project will encourage more conversations between machine learning experts, disease ecologists, museum curators, and public health stakeholders. This type of interdisciplinary and international collaboration is fundamental to outbreak prediction and prevention.</p>

<p><em>F﻿ind out more about Maya’s research <a href="https://mayajuman.github.io/">here.</a></em></p>

<p><em>M﻿aya’s project is funded through the Accelerare-C2D3 funding call. Find out more about the call and the projects funded in 2023 <a href="https://acceleratescience.github.io/news/2023-10-26-pursuing-innovative-applications-of-ai-in-research-and-real-world-contexts-%E2%80%93-announcing-our-2023-projects.html">here</a>.</em></p>]]></content><author><name>Maya Juman, PhD student, Department of Veterinary Medicine</name></author><category term="machine-learning" /><summary type="html"><![CDATA[Bats comprise around one in five named mammal species and are found on every continent except Antarctica. In recent decades, bats have been implicated as potential hosts of several viruses that cause high fatality rates in humans. Still, despite years of research, there’s a lot we don’t know about bat virus ecology, hindering the ability of experts to anticipate and prepare for the next potential pandemic. A repository of untapped data could help shed light on the relationship between bat ecology and viral emergence. In my project, supported by the Accelerate and Cambridge Centre for Data Driven Discovery funding call, I am exploring using AI and natural history museum collections for host prediction and viral surveillance.]]></summary><media:thumbnail xmlns:media="http://search.yahoo.com/mrss/" url="http://localhost:4000/assets/uploads/maya-juman-blog-image-march-2024.jpg" /><media:content medium="image" url="http://localhost:4000/assets/uploads/maya-juman-blog-image-march-2024.jpg" xmlns:media="http://search.yahoo.com/mrss/" /></entry><entry><title type="html">How can we … use AI to find drug combinations to aid cancer research?</title><link href="http://localhost:4000/2024/03/04/how-can-we-use-ai-to-find-drug-combinations-to-aid-cancer-research.html" rel="alternate" type="text/html" title="How can we … use AI to find drug combinations to aid cancer research?" /><published>2024-03-04T10:30:00+00:00</published><updated>2024-03-04T10:30:00+00:00</updated><id>http://localhost:4000/2024/03/04/how-can-we-%E2%80%A6-use-ai-to-find-drug-combinations-to-aid-cancer-research</id><content type="html" xml:base="http://localhost:4000/2024/03/04/how-can-we-use-ai-to-find-drug-combinations-to-aid-cancer-research.html"><![CDATA[<p>Overcoming drug resistance is one goal of cancer research<a href=""></a>Experts are exploring whether combinations of treatments could make current drugs work better, leading to better outcomes for patients. But pinpointing potentially successful combinations – what we refer to as synergistic combinations – of drugs is far from simple.</p>

<p>My research, in collaboration with AstraZeneca, focuses on analysing and predicting the synergies of drug combinations. There are two parts to my project.</p>

<p><strong>Part one: Improved estimation of synergies</strong></p>

<p>There are a number of quantification frameworks that estimate the synergistic effect of drug combinations – simply put, how effectively they work in combination with each other – but disagreements in these estimates make it challenging for scientists to determine the best combinations to focus on for drug screening. For example, they try to summarise multiple aspects of drug combinations, including their efficacy and toxicity into a single score.</p>

<p>Furthermore, the lack of accurate uncertainty quantification for those estimates means they can’t be directly used to choose optimal drug combinations based on the most favourable synergistic effect, due to the potentially large uncertainties behind the synergy scores.</p>

<p>Estimating the synergy of drug combinations where we already have relevant data was the first part of the project. My supervisor at Cambridge, Carl Henrik Ek, Marta Milo at AstraZeneca and Magnus Rattray at the University of Manchester and I came up with SynBa, a flexible Bayesian approach to estimate the uncertainty of the synergistic efficacy and potency of drug combinations. We published our findings in the <a href="https://academic.oup.com/bioinformatics/article/39/Supplement_1/i121/7210462">Journal of Bioinformatics</a> earlier this year.</p>

<p>Through experiments on large combination screenings and comparison against benchmark methods, we showed that SynBa provides improved accuracy of dose–response predictions and better-calibrated uncertainty estimation for the parameters and the synergies.</p>

<p>We’re using a Bayesian framework, which treats quantities as random variables instead of fixed values. This means we can look at the quantities of interest in our outputs as a distribution instead of single estimates, allowing us to estimate how uncertain they are. This is useful because there are cases when it might look like a particular combination of two drugs has great potential, but where biological data is hugely uncertain and contains a large amount of noise from sources that are difficult to understand. Our approach identifies the drug combinations with a high and confident synergy score that can be trusted. In the meantime, SynBa can also flag those combinations with a synergistic but highly uncertain score, in which case more measurements would be required to reduce the uncertainty over the decision to a satisfying level.</p>

<p><strong>Part two: Navigating an unexplored space</strong></p>

<p>The second part of my thesis is about predicting the synergy of unexplored drug combinations, utilising the model I built in the first part and the existing pharmacological, biological and chemical data from combination screenings. The data we are working from are all cell lines in vitro.</p>

<p>Using machine learning in this way could help scientists explore the possibilities of combining single drugs in a large unexplored space where there are tens of thousands of candidates. Predicting which ones are most likely to work best could really speed things up, allowing scientists to focus on the most promising combinations. The model we are building and refining is not intended to be a magical end-to-end solution but a tool to help biologists narrow down candidates effectively and help decide what could be interesting combinations.</p>

<p>We’re focusing on providing an uncertainty estimation alongside each prediction, which will enable decision-making to be informed by the confidence level associated with the prediction.<a href=""></a></p>

<p><strong>A winning combination</strong></p>

<p>This technology focuses on identifying the drug combinations that target cancer cell lines. Our dataset mainly consists of breast, lung and bladder cell lines.</p>

<p>We are building our model to be open source and hope it will be helpful to the community of scientists identifying drug combinations to fight cancer. While we are still developing the model, iterating and working with biologists to refine it, we hope it could one day be used by AstraZeneca for real-world development.</p>

<p>I share the vision of the Accelerate Programme for Scientific Discovery and my supervisors of the potential for AI to accelerate scientific discovery and am working to create tools to help scientists solve difficult problems. While I do not know what the future holds, I intend to pursue a career in machine learning and health data science either as an academic researcher or in industry, with the aim of helping to speed up the drug discovery pipeline, especially in the pre-clinical phase.</p>]]></content><author><name>By Haoting Zhang, HDRUK-Turing Wellcome PhD Student  Department of Computer Science and Technology </name></author><summary type="html"><![CDATA[Overcoming drug resistance is one goal of cancer research. Experts are exploring whether combinations of treatments could make current drugs work better, leading to better outcomes for patients. But pinpointing potentially successful combinations – what we refer to as synergistic combinations – of drugs is far from simple.]]></summary><media:thumbnail xmlns:media="http://search.yahoo.com/mrss/" url="http://localhost:4000/assets/uploads/haoting.png" /><media:content medium="image" url="http://localhost:4000/assets/uploads/haoting.png" xmlns:media="http://search.yahoo.com/mrss/" /></entry><entry><title type="html">How can we… use AI to advance metabolic medicine?</title><link href="http://localhost:4000/accelerate-spark-data-science-residency/machine-learning/2024/02/19/how-can-we-use-ai-to-advance-metabolic-medicine.html" rel="alternate" type="text/html" title="How can we… use AI to advance metabolic medicine?" /><published>2024-02-19T11:45:00+00:00</published><updated>2024-02-19T11:45:00+00:00</updated><id>http://localhost:4000/accelerate-spark-data-science-residency/machine-learning/2024/02/19/how-can-we%E2%80%A6-use-ai-to-advance-metabolic-medicine</id><content type="html" xml:base="http://localhost:4000/accelerate-spark-data-science-residency/machine-learning/2024/02/19/how-can-we-use-ai-to-advance-metabolic-medicine.html"><![CDATA[<p>We are currently battling an obesity pandemic, with worldwide rates almost tripling since 1975  . There is understandably a large and urgent interest in better understanding the underlying mechanisms that contribute to obesity, including how the gut hormones may be involved. Analogues of the gut hormone GLP-1 such as Ozempic and Wegovy are now used to treat both diabetes and obesity.</p>

<p>My research looks at how gut hormones levels and other markers of metabolism change in healthy individuals compared to patients with obesity, and also compared to patients with bowel conditions which impact 6.5 million people in the UK.</p>

<p><br />
<strong>My research</strong></p>

<p>I am a medical doctor more than halfway through my PhD in gut hormone physiology in the Gribble-Reimann group at the Institute of Metabolic Science, University of Cambridge.  I study gut hormones involved in appetite, satiety and motility. I study levels of certain gut hormones in the fed and fasted states in healthy people and those with different bowel conditions, recruiting participants and using new techniques in the lab to measure levels of different hormones and other metabolic markers. I regularly collaborate with the clinical endocrinology and gastroenterology teams at Addenbrooke’s Hospital. I aim to characterise these levels in healthy volunteers and look at how they vary in different disease states.</p>

<p>Most people in my field of research look at gut hormones and how they are connected to diabetes or obesity because they are appetite and metabolism, but I’m predominantly interested in what regulates the release of hormones that either slow down or speed up processes in the gut.</p>

<p>There are around 20 hormones produced in the gut.  The most studied gut hormone to date is glucagon like peptide-1 (GLP-1) which is involved in controlling blood glucose and appetite, but also slows down how food move through the gut.  GLP-1 analogues are now used for treatment of obesity, but has also been additionally recognised recently a treatment for patients with bile acid diarrhoea (BAD).  I not only study GLP-1, but other much less studied hormones including motilin and insulin-like peptide 5 and how they are involved in gut motility.</p>

<p>One condition I have particularly focused on is bile acid diarrhoea (BAD) that affects around one million people  in the UK. Bile is known to stimulate lots of different hormones from the gut, so we have chosen to focus on this condition to try and understand these hormones in more detail, and how their hormone levels compare to individuals with other bowel conditions, and healthy volunteers.</p>

<p>Our group in collaboration with Richard Kay uses liquid chromatography mass spectroscopy for greater specificity and the opportunity to test for novel biomarkers, as well as data from other studies, which together could potentially aid in the diagnosis and treatment of different gastrointestinal and metabolic diseases including BAD.</p>

<p><strong>Making data more digestible</strong></p>

<p><br />
As part of my research, I wanted to integrate different data sets to explore measured gut hormones, demographics features and metabolic markers across different conditions, but it proved difficult to merge and analyse without a data science background.</p>

<p>So, to develop the skills I needed, I took the Accelerate Programme’s 5-week Introducing Data Science for Research course and learned the basics of Python, which I enjoyed. It allowed me to learn and master the basics of data preprocessing and merging using the pandas and numpy packages, alongside being to produce much higher quality data visualisations using the seaborn package.  This has elevated my work by merging databases effectively and doing quick high quality visualisations to present data in more aesthetic ways.</p>

<p>I then took the Accelerate Programme’s year-long Machine Learning Academy.  I am using the skills I learned to take my data further.  I have so far used unsupervised and supervised algorithms to explore   predicted gut hormone levels in obesity, whilst using ensemble techniques to explore proteomic datasets to find novel biomarkers in different bowel conditions. I hope to be able to predict whether someone’s gut hormone or metabolic marker levels are that of a healthy person, or whether they have a metabolic or bowel condition.</p>

<p>Since completing the course, I have attended a Machine Learning Engineering Clinic with Accelerate’s Machine Learning Engineer Ryan Daniels  to sense-check my data techniques with an expert, as the majority of my group are clinical or biological scientists with less experience in computer science. Ryan helped me further develop my data science skills, and has provided expertise in feature selection processes to help find import biomarkers in my datasets.. We are collaborating on a forthcoming project involving big databases incorporating different conditions and hundreds of different protein fragment readouts. With the techniques Ryan has shown me, I should be able to see which fragments cluster in one set versus another.</p>

<p><strong>The future</strong></p>

<p>I will be presenting some of my findings at the Digestive Diseases Week in USA later this year. I feel I have found my niche – looking at gastroenterology from a hormone point of view – and plan to continue looking at gut hormone levels and try to unravel the sort of dysfunction that occurs with different conditions. I would also like to continue following a big data approach as well as seeing individuals in the clinic. It’s an exciting area. Currently, people look to diet or their microbiome to relieve symptoms of IBS and other issues, but I think there is a piece of the puzzle missing: gut hormone levels.</p>

<p>I hope to carry on collaborating to help find this missing piece and use big data, machine learning and AI to find new biomarkers to diagnose conditions or suggest if one treatment would work better than another. I hope to take what I’ve learned on the Accelerate courses to address those questions.</p>

<p><em>Find out more about the data science and machine learning courses offered by the Accelerate Programme on our <a href="https://acceleratescience.github.io/resources">resources page</a> or get in touch at accelerate-science@cst.cam.ac.uk.</em></p>

<p><em>Accelerate’s Machine Learning Engineering Clinic is available to all researchers at the University of Cambridge to support you in implementing machine learning at all stages of the research pipeline. <a href="https://acceleratescience.github.io/machine-learning-clinic">Find out more</a> and contact us.</em></p>]]></content><author><name>Christopher Bannon, Registrar Clinical Research Associate in Metabolic Medicine, University of Cambridge  </name></author><category term="accelerate-spark-data-science-residency" /><category term="machine-learning" /><summary type="html"><![CDATA[We are currently battling an obesity pandemic, with worldwide rates almost tripling since 1975 . There is understandably a large and urgent interest in better understanding the underlying mechanisms that contribute to obesity, including how the gut hormones may be involved. Analogues of the gut hormone GLP-1 such as Ozempic and Wegovy are now used to treat both diabetes and obesity.]]></summary><media:thumbnail xmlns:media="http://search.yahoo.com/mrss/" url="http://localhost:4000/assets/uploads/a65i6726.jpg" /><media:content medium="image" url="http://localhost:4000/assets/uploads/a65i6726.jpg" xmlns:media="http://search.yahoo.com/mrss/" /></entry><entry><title type="html">AI for Science Summit – driving progress as a community</title><link href="http://localhost:4000/2024/02/13/ai-for-science-summit-driving-progress-as-a-community.html" rel="alternate" type="text/html" title="AI for Science Summit – driving progress as a community" /><published>2024-02-13T16:25:00+00:00</published><updated>2024-02-13T16:25:00+00:00</updated><id>http://localhost:4000/2024/02/13/ai-for-science-summit-%E2%80%93-driving-progress-as-a-community</id><content type="html" xml:base="http://localhost:4000/2024/02/13/ai-for-science-summit-driving-progress-as-a-community.html"><![CDATA[<p>Alongside the AI for Science community here in Cambridge, colleagues across other institutions in the network of AI programmes funded by Schmidt Futures are also drawing together communities of like-minded scientists. In December 2023, in collaboration with the Schmidt Futures funded programmes at Imperial College London and the University of Oxford, the Accelerate Programme hosted an AI for Science summit bringing together over 100 researchers working in AI for Science across the UK, US and Asia.</p>

<p><strong>Diverse applications with shared challenges</strong></p>

<p>Across the two days, talks and panel discussions explored a range of applications of AI across diverse disciplines from the use of AI in polar research, work with industry on supply chains to applications in chemical discovery. Despite the diversity of topics explored, a number of shared challenges and opportunities emerged including the challenges of working across disciplines, closing the loop from innovation to implementation and working with incomplete data.</p>

<p>As well as shared challenges, insights on best practice also emerged with unworkshops on large language models and software engineering highlighting the importance of collaboration and openness and clarity.</p>

<p><br />
<strong>AI for Science pioneers</strong></p>

<p>Keynote speaker, Shakir Mohamed (Research Director, DeepMind and Associate Fellow, Leverhulme Centre for the Future of Intelligence), explored the role of generative AI in scientific discovery and highlighted the role of AI for Science practitioners as pioneers.</p>

<p>Practitioners are both working at the frontier of new horizons of generative AI for Science and defining what these new horizons are. As this new role of pioneers emerges, coming together as a community provides the opportunity to explore how we can shape the field as we work together to accelerate progress.</p>

<p><strong>Taking the next steps to reach the potential of AI for Science</strong></p>

<p>The final unworkshop drew together participants to consider what steps we can take as a community to achieve the full potential of AI for Science. As well as increased communication within the community, the need to collaborate with domain experts was also highlighted as a crucial step. Building trust is also key, both by improving explainability and by sharing negative results.</p>

<p><br />
Across the two days, both the potential of AI to enable new discoveries and the power of the community to realise this potential were evident. By working together, sharing research and best practice, the AI for Science community can have real impact in enabling the next wave of AI driven discoveries.</p>

<p><em>Thank you to all of our speakers, panellists and participants for their contributions across the two days of discussion.</em></p>

<p><em>If you are interested in taking part in future community events, please contact the team on accelerate-science@cst.cam.ac.uk.</em></p>

<p><em>Artist Dan Andrews recorded discussions from the day in a series of graphic captures which can be viewed <a href="https://acceleratescience.github.io/assets/uploads/ai-for-science-summit-11-12-december-2023-graphics.pdf">here.</a></em></p>

<p><em>A selection of photographs from the event can be viewed <a href="https://drive.google.com/drive/folders/1pYR8Aqy4c0lKPd4a_Dkvgu_d1AIz4qmh?usp=sharing">here. </a></em></p>]]></content><author><name></name></author><summary type="html"><![CDATA[Alongside the AI for Science community here in Cambridge, colleagues across other institutions in the network of AI programmes funded by Schmidt Futures are also drawing together communities of like-minded scientists. In December 2023, in collaboration with the Schmidt Futures funded programmes at Imperial College London and the University of Oxford, the Accelerate Programme hosted an AI for Science summit bringing together over 100 researchers working in AI for Science across the UK, US and Asia.]]></summary><media:thumbnail xmlns:media="http://search.yahoo.com/mrss/" url="http://localhost:4000/assets/uploads/a65i7877.jpg" /><media:content medium="image" url="http://localhost:4000/assets/uploads/a65i7877.jpg" xmlns:media="http://search.yahoo.com/mrss/" /></entry><entry><title type="html">Can we… use AI to better treat brain cancer?</title><link href="http://localhost:4000/accelerate-spark-data-science-residency/2024/01/31/can-we-use-ai-to-better-treat-brain-cancer.html" rel="alternate" type="text/html" title="Can we… use AI to better treat brain cancer?" /><published>2024-01-31T09:52:00+00:00</published><updated>2024-01-31T09:52:00+00:00</updated><id>http://localhost:4000/accelerate-spark-data-science-residency/2024/01/31/can-we%E2%80%A6-use-ai-to-better-treat-brain-cancer</id><content type="html" xml:base="http://localhost:4000/accelerate-spark-data-science-residency/2024/01/31/can-we-use-ai-to-better-treat-brain-cancer.html"><![CDATA[<p>Glioblastoma is a common brain cancer, yet there have been few significant advances in treatment for over a decade. For patients who are diagnosed with glioblastoma, the prognosis is poor. On average, they have just 15 to 20 months to live, even with an optimum combination of surgery, followed by chemotherapy and radiotherapy. During that time, their quality of life is negatively impacted. The challenge is to develop a new treatment that can improve patients’ prognosis in terms of survival and quality of life.</p>

<p><strong>Current treatment</strong></p>

<p>Symptoms of glioblastoma typically include headaches, cognitive problems and sometimes seizures. The cancer shows up on MRI scans as a big lump in the brain, but neuroscientists know it has usually infiltrated beyond what can be seen. When they operate, surgeons remove as much of the lump as is safely possible, while knowing it will probably not be the whole cancer. Currently, we do not have a lot of data to show how the surgery will affect patients ability to think and it is difficult to predict how long individual patients will live for, so we can’t give them any detailed information before the surgery. Despite chemotherapy and radiotherapy following surgery, in 90% of cases, the tumour will return within six months and despite our best efforts at treatment, patients deteriorate rapidly and then die.</p>

<p><strong>Scanning for answers</strong></p>

<p>In my lab in the Department of Clinical Neurosciences, we are trying to develop different types of MRI scans to better see tumours. This involves using AI to draw segmentations and calculate the volume of tumours, which can predict patient survival before their operation. Furthermore, if we can see tumours better, we can improve how to do surgery to remove more tumours safely.</p>

<p>We are also interested in using a battery of neuropsychology tests that link with imaging to measure cognition before and after surgery is carried out and build a model of how the brain and tumour interact. This method allows us to see which other parts of the brain may be affected by a tumour, giving us the option of performing surgery or giving radiotherapy to additional parts of the brain to improve the prognosis of patients.</p>

<p>Our current data shows that the majority of patients with glioblastoma already suffer from a degree of cognitive problems before their operation. In the first week after an operation, they will typically experience a worsening of that cognitive function, which may be related to swelling, medication or the fact they are in hospital. However, unexpectedly by four to six weeks after surgery when they start chemotherapy or radiotherapy, many patients improve compared to early after surgery. Despite this, they will never recover the cognition they had before surgery, so the damage the tumour has caused will not go away. This means that surgery may not be causing the permanent additional damage that we feared.</p>

<p>While this may sound pessimistic, having a better picture of the damage caused gives surgeons some cause for optimism, because we can model future treatment and possibly remove damaged parts of the brain that we know will not recover, which could enable us to treat the cancer more aggressively.</p>

<p>Another avenue to investigate is why some patients improve better than others. I hypothesise that it is related to the intimal damage that a tumour has done, but everyone is unique and behaves differently, which is why I am using mathematical techniques and AI to model the degree of cognitive improvement taking individual variability into account.</p>

<p><strong>Accelerating research</strong></p>

<p>I come from a clinical background so machine learning, computational methods and coding were new to me before I started by PhD three years ago.  So, the Accelerate Programme’s Python course, Data Science Residency and Machine Learning Academy were all invaluable. I wouldn’t have been able to analyse medical images in the way I do without learning how to code and how to implement the algorithms and computational techniques we discussed on the courses. It also taught me how to think about high-dimensional problems involving extracting meaning from different-sized datasets and variables such as decoding how the cognition with MRI.</p>

<p><strong>Looking to the future</strong></p>

<p>I am currently involved in setting up a clinical trial so we will be able to go beyond the standard care for glioblastoma, by using imaging biomarkers to show the invasion of a tumour. This will be the first time we have an imaging biomarker that could change how we perform surgery, which is exciting.</p>

<p>In the short to medium term, I want to combine my clinical career with academic research in brain tumours. I want to continue my research looking at developing biomarkers of tumour-brain interaction and tumour damage. Hopefully, by the time I’ve finished my neurosurgical clinical training, I can start planning a clinical trial to look at how we can do surgery or radiotherapy differently based on the effect of tumour damage on the brain.</p>

<p>AI is already being used to label tumours on CT scans and in radiotherapy planning for other cancers, so hopefully I can use the technology to contribute to significant advances in glioblastoma treatment that is badly needed.</p>]]></content><author><name> Yizhou Wan, Neurosurgical trainee (Registrar) at Oxford University Hospitals and CRUK Clinical Research Training Fellow, Clinical Neurosciences, University of Cambridge</name></author><category term="accelerate-spark-data-science-residency" /><summary type="html"><![CDATA[Glioblastoma is a common brain cancer, yet there have been few significant advances in treatment for over a decade. For patients who are diagnosed with glioblastoma, the prognosis is poor. On average, they have just 15 to 20 months to live, even with an optimum combination of surgery, followed by chemotherapy and radiotherapy. During that time, their quality of life is negatively impacted. The challenge is to develop a new treatment that can improve patients’ prognosis in terms of survival and quality of life.]]></summary><media:thumbnail xmlns:media="http://search.yahoo.com/mrss/" url="http://localhost:4000/assets/uploads/yizhou-wan.jpg" /><media:content medium="image" url="http://localhost:4000/assets/uploads/yizhou-wan.jpg" xmlns:media="http://search.yahoo.com/mrss/" /></entry><entry><title type="html">How can we… use AI to help smallholder farmers in Uganda?</title><link href="http://localhost:4000/machine-learning/2024/01/08/how-can-we-use-ai-to-help-smallholder-farmers-in-uganda.html" rel="alternate" type="text/html" title="How can we… use AI to help smallholder farmers in Uganda?" /><published>2024-01-08T09:30:00+00:00</published><updated>2024-01-08T09:30:00+00:00</updated><id>http://localhost:4000/machine-learning/2024/01/08/how-can-we%E2%80%A6-use-ai-to-help-smallholder-farmers-in-uganda</id><content type="html" xml:base="http://localhost:4000/machine-learning/2024/01/08/how-can-we-use-ai-to-help-smallholder-farmers-in-uganda.html"><![CDATA[<p>Agriculture accounts for over 40% of Uganda’s GDP, employs 80% of the working population and makes up 85% of exports, such as delicious coffee and cocoa beans for chocolate.</p>

<p>Yet, the farmland is primarily rain-fed, making it vulnerable to drought, and Ugandan smallholder farmers are among the most affected by the impacts of climate change, according to <a href="https://unfccc.int/climate-action/momentum-for-change/ict-solutions/enabling-farmers-to-adapt-to-climate-change">the UN</a>.</p>

<p>To help farmers cope with the effects of higher average temperatures and changing rainfall patterns, which result in a reduction in food security and a decline in the quantity and quality of water, there are radio programs that share weather forecasts and other helpful information such as disease hotspots to help them minimise crop loss.</p>

<p>My team at the <a href="https://air.ug/">Makerere Artificial Intelligence Lab</a> is harnessing AI and applying it to <a href="https://air.ug/project/3/details">problems facing farmers</a>, including crop disease surveillance. We take an end-to-end approach that begins by understanding the user’s problem and then works on the technical aspects of the project, before deploying useful AI systems.</p>

<p>In the Spring of 2023, I travelled to Cambridge with my colleague Andrew Katumba, to connect with other researchers involved in the Accelerate Programme for Scientific Discovery who are using AI in their quest to improve the development of AI systems for use by smallholder farmers in the provision of agricultural services.</p>

<p><strong>Planting the seed of the project</strong></p>

<p>Our project began by crowdsourcing information about crop pests and diseases nationwide. We worked with agricultural experts to ask farmers to take geotagged photos of their crops using mobile phones. We built up a map using these crowdsourced images and photos taken which enabled us to see the spread of diseases over months as information kept pouring in.</p>

<p>We thought it would be interesting to overlay this information with speech data about crop blights collected from radio broadcasts that frequently share information or host call-ins for agricultural workers with burning questions. As internet access is unavailable in remote areas, many farmers rely on radio shows for information.</p>

<p><strong>Growing our dataset</strong></p>

<p>Before we could build speech recognition models designed to listen to the radio, it was necessary to build language datasets to train the models to understand local languages. We collaborated with Mozilla to use its <a href="https://commonvoice.mozilla.org/en">Common Voice platform</a>, which is a crowdsourcing project that is designed to teach machines how people speak in a bid to make voice recognition software open and accessible to everyone.</p>

<p>Working with linguists, we collected scripts and text for people to read and reached out to experts with links to communities in the Buganda Kingdom in Uganda. In this way, we were able to record voices using Mozilla’s platform and collect agricultural voice data in Luganda using an in-house mobile app called “Yogera”. Luganda is the Bantu language of the Baganda people and is widely used in Uganda, with more than two million speakers.</p>

<p>This process enabled us to get good-quality speech data upon which we could start building our natural language processing (NLP) models. We used the speech recognition models to listen in to radio broadcasts during the COVID-19 and Ebola pandemics in Uganda to understand people’s sentiments around the government interventions to stop their spread.</p>

<p><br />
Just like science, agriculture has its own vocabulary. We needed to harness spoken examples of this vocabulary to train our general NLP model to become domain-specific. Luckily, we had access to a treasure trove of examples thanks to smallholder farmers we had previously worked with and were able to add specific agricultural data to our model. We are currently improving the model and plan to roll out an updated version of the system to farmers.</p>

<p><strong>Weeding out problems</strong></p>

<p>We collaborated with smallholder farmers to crowdsource images of their crops via our Adsurv surveillance mobile application. This project evolved into a question and answering service where farmers could send a question to an agricultural expert, such as “There is cassava mosaic disease nearby, what can I do and where can I get help?” but it proved so popular the experts became overwhelmed.</p>

<p>We decided to use the previously collected questions and answers to build an AI model capable of providing agricultural advice. The current system is based on natural language processing (NLP) processes and features models for: language identification, automatic speech recognition in both English and Luganda, question similarity, and topic categorisation. Essentially, the AI model compares the similarity of a question a farmer has asked with the previously asked questions. If the farmer doesn’t like the advice, they can connect with a human expert. While the AI works, we found that not all the farmers were familiar with English, and were more comfortable speaking their local languages, so we have found another application for the speech models we built.</p>

<p><strong>Helping farmers flourish</strong></p>

<p>Building automatic speech recognition for the agricultural domain with the intention of helping farmers is at the heart of our work. Our mobile app now offers a voice-enabled question-answering system for smallholder farmers to conversationally access feedback to their inquiries based on expert opinions, using AI. It also enables farmers to upload photos of their crops and receive machine learning-based disease diagnosis and advisory in their local languages.</p>

<p><strong>A fertile future</strong></p>

<p>Having built a community and collected a body of data, we see ways in which we can extend our work. For example, we are partnering with Gudie Leisure Farm - a social enterprise that helps smallholder farmers become eco-entrepreneurs – which we hope will enable us to scale our app and increase the number of young farmers using our advisory system. We also plan to increase its reach by adding multiple Ugandan and African languages.</p>

<p>Finally, we intend to work with researchers in the <a href="https://mlatcl.github.io/">ML@CL group</a> at the University of Cambridge building on collaborations from our visit, to build and evaluate an edge computing architecture for deploying the question-answering system in rural areas with Internet connectivity limitations.</p>]]></content><author><name>Joyce Nakatumba-Nabende, Head of the Makerere Artificial Intelligence Lab and Senior Lecturer in the Department of Computer Science at Makerere University, Uganda</name></author><category term="machine-learning" /><summary type="html"><![CDATA[My team at the Makerere Artificial Intelligence Lab is harnessing AI and applying it to problems facing farmers, including crop disease surveillance. We take an end-to-end approach that begins by understanding the user’s problem and then works on the technical aspects of the project, before deploying useful AI systems.]]></summary><media:thumbnail xmlns:media="http://search.yahoo.com/mrss/" url="http://localhost:4000/assets/uploads/joyce-nabende-blog-january-2024-1-.jpg" /><media:content medium="image" url="http://localhost:4000/assets/uploads/joyce-nabende-blog-january-2024-1-.jpg" xmlns:media="http://search.yahoo.com/mrss/" /></entry><entry><title type="html">Accelerate Science Machine Learning Engineering Clinic</title><link href="http://localhost:4000/2023/12/14/accelerate-science-machine-learning-clinic.html" rel="alternate" type="text/html" title="Accelerate Science Machine Learning Engineering Clinic" /><published>2023-12-14T09:21:00+00:00</published><updated>2023-12-14T09:21:00+00:00</updated><id>http://localhost:4000/2023/12/14/accelerate-science-machine-learning-clinic</id><content type="html" xml:base="http://localhost:4000/2023/12/14/accelerate-science-machine-learning-clinic.html"><![CDATA[<p>The Accelerate Programme for Scientific Discovery aims to drive a step change in the use of AI for science across the University of Cambridge. To get there, the programme has been exploring ways of supporting researchers using AI, no matter their background.</p>

<p>In 2022, the programme started a Machine Learning Engineering Clinic as part of its support package, with Clinic sessions convened both online, and in departments around the university. The clinics are run by scientists and engineers from the Accelerate Science programme, with the goal of connecting researchers and AI experts. From these clinics, we’ve answered over 80 support tickets across 35 university departments.</p>

<p>The clinic can help a range of issues that researchers encounter in AI for science projects: from brainstorming which machine learning methods to use, through best-practices around publishing software packages, to fine-tuning large language models. No question is too small - sometimes all you need is a short chat with one of our engineers to sanity check your work. We’re even available to help grant applications for research using machine learning.</p>

<p>A great example is an ongoing consultation with Chris Bannon, a researcher from the Wellcome-MRC Institute of Metabolic Science and a former ML Academy student. Chris has done an enormous amount of work applying machine learning to studying gastrointestinal conditions and hormone levels using blood data. Our consultations have ranged from in depth discussions about particular machine learning and evaluation methods, to quick checks of algorithm implementations.</p>

<p>Chris says <em>“I have used the machine learning clinic 3 times over the autumn, and have found their input invaluable. As a clinical research associate, I am the only member of my team performing data science, and the machine learning clinic has not only helped me further my data analysis, but also develop my skills as a data scientist. I fully recommend their services, and have been very grateful for their input and assistance.”</em></p>

<p>On the other hand, if you have a bigger task, we’re able to dive in and help. Three of the bigger projects we’ve advised on have included:</p>

<ul>
  <li><strong>Building open source software</strong>: formal thought disorder shows up in the way that people speak. They tend to jump between topics rather than create a coherent narrative. In this project, Caroline Nettekoven from the Department of Psychiatry, <a href="https://acceleratescience.github.io/2023/04/03/engineering-a-model-to-help-learn-more-about-schizophrenia.html">developed a pipeline</a> to show semantic connections in transcripts of people’s speech, which could then be analysed to compare patients with formal thought disorders against a control from the general population. Caroline wrote and packaged this software with help from the Turing Institute and was aiming to release the software for general use alongside her paper. Over a period of 8 weeks, we helped shape the code so that it was able to be released on time.</li>
  <li><strong>Exploring machine learning models</strong>: Aditya Ravuri from the Department of Computer Science and Technology and Jen Muir from the ARU Behavioural Ecology Research Group developed a model to detect calls in coppery titi monkeys, a South American primate. Traditional human sound event detection models perform poorly on monkey calls, prompting Aditya and Jen to explore different models. Their aim is to both predict when a call occurs, and what type of call it is. This should help researchers and zoo staff determine whether the monkeys are in distress. Jen and Aditya put in a tremendous amount of work to build a high quality dataset, and with the help of the ML Clinic, were able to explore alternative models for detecting and classifying these calls.</li>
  <li><strong>Understanding new AI methods, such as Large Language Models</strong>: Words often carry multiple meanings, which can vary significantly based on the context in which they are used. For instance, the word “bat” can refer to a nocturnal flying mammal or a piece of sports equipment. This linguistic phenomenon presents a challenge: how can we effectively categorise words into hierarchies based on the ease with which their meanings can be discerned from context? Nina Haket, from the Department of Theoretical and Applied Linguistics, is using large language models to systematically organise words and better understand how they’re used in different contexts, with the help of the ML Clinic.</li>
</ul>

<p>Nina says: “<em>Ryan and the ML Clinic have been invaluable in the project. Since I had little experience with LLMs and ML, the task I wanted to do seemed daunting and I spent months trying to solve it on my own. With their help, we now have it up and running, and should get some interesting results soon.”</em></p>

<p>The variety of projects highlighted here reflects the broad range of assistance provided by the Machine Learning Engineering Clinic across the University of Cambridge - from supporting health research, to complex linguistic analysis, our team can offer practical AI and ML guidance.</p>

<p>We’ve worked with departments across the university to host in-person clinic sessions. To host in your department, all we need from you is a room booking to hold the clinic in, and some help advertising in your department. <a href="mailto:accelerate-mle@cst.cam.ac.uk">Get in touch</a> with us to fix a date.</p>

<p>And if you have an ML problem that you’d like support with and can’t make it to a clinic, don’t worry. You can still file a <a href="https://forms.office.com/Pages/ResponsePage.aspx?id=RQSlSfq9eUut41R7TzmG6SaVOxbmBOdAg9GzbnrB5IRUNDhIUjNCRkI0SjFaV1Y2VDRTR1pPWTNKOS4u">support ticket</a> with us and we’ll be in touch!</p>

<p>Whether it’s a short, one-time consultation or a longer-term collaborative effort, our goal is to make advanced AI tools more accessible and effective for all researchers at the university.</p>]]></content><author><name></name></author><summary type="html"><![CDATA[The Accelerate Programme for Scientific Discovery aims to drive a step change in the use of AI for science across the University of Cambridge. To get there, the programme has been exploring ways of supporting researchers using AI, no matter their background. In 2022, the programme started a Machine Learning Engineering Clinic as part of its support package, with Clinic sessions convened both online, and in departments around the university. The clinics are run by scientists and engineers from the Accelerate Science programme, with the goal of connecting researchers and AI experts. From these clinics, we’ve answered over 80 support tickets across 35 university departments.]]></summary><media:thumbnail xmlns:media="http://search.yahoo.com/mrss/" url="http://localhost:4000/assets/uploads/img_8991.jpg" /><media:content medium="image" url="http://localhost:4000/assets/uploads/img_8991.jpg" xmlns:media="http://search.yahoo.com/mrss/" /></entry></feed>